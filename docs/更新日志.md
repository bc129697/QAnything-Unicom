# 更新日志
## 2024.09.24 —— commit：
* 修改：
    * 支持gpu推理，默认使用第0张卡,ocr、pdf解析服务、embedding服务、rerank服务
    * 打印每个接口返回内容到debug_logger
    * 去掉new_knowledge_base接口中的is_quick参数
    * 修改delete_knowledge_base，只支持删除单个知识库，且删除mysql中的KnowledgeBase和File（原方法为delete状态置1），解决删除后无法新增同kb_id知识库的问题


* 特点：
    * 单个知识库限定最大文件数量1000





## 2024.09.25 —— commit：
* 接口通过大模型改写query
condense_q_system_prompt = """
假设你是极其专业的英语和汉语语言专家。你的任务是：给定一个聊天历史记录和一个可能涉及此聊天历史的用户最新的问题(新问题)，请构造一个不需要聊天历史就能理解的独立且语义完整的问题。

你可以假设这个问题是在用户与聊天机器人对话的背景下。

instructions:
- 请始终记住，你的任务是生成独立问题，而不是直接回答新问题！
- 根据用户的新问题和聊天历史记录，判断新问题是否已经是独立且语义完整的。如果新问题已经独立且完整，直接输出新问题，无需任何改动；否则，你需要对新问题进行改写，使其成为独立问题。
- 确保问题在重新构造前后语种保持一致。
- 确保问题在重新构造前后意思保持一致。
- 在构建独立问题时，尽可能将代词（如"她"、"他们"、"它"等）替换为聊天历史记录中对应的具体的名词或实体引用，以提高问题的明确性和易理解性。

```
Example input:
HumanMessage: `北京明天出门需要带伞吗？`
AIMessage: `今天北京的天气是全天阴，气温19摄氏度到27摄氏度，因此不需要带伞噢。`
新问题: `那后天呢？`  # 问题与上文有关，不独立且语义不完整，需要改写
Example output: `北京后天出门需要带伞吗？`  # 根据聊天历史改写新问题，使其独立

Example input:
HumanMessage: `明天北京的天气是多云转晴，适合出门野炊吗？`
AIMessage: `当然可以，这样的天气非常适合出门野炊呢！不过在出门前最好还是要做好防晒措施噢~`
新问题: `那北京哪里适合野炊呢？`  # 问题已经是独立且语义完整的，不需要改写
Example output: `那北京哪里适合野炊呢？` # 直接返回新问题，不需要改写
```

"""

[
    ("system", self.condense_q_system_prompt),
    MessagesPlaceholder(variable_name="chat_history"),
    ("human", "新问题:{question}
    请构造不需要聊天历史就能理解的独立且语义完整的问题。
    独立问题:"),
]



## 2024.10.10 —— commit：
* 修改：
    * 检索返回socre为float
    * 检索返回字段为retrieval_documents
    * 增加pdf文件的page_id字段检测方法，在文档中增加特殊页码字段，在chunk split时检出替换，修改原page_id属性结果
    * 增加query改写接口，用于改写query
    * 增加删除知识库或文件时，同时删除本地文件
    * 增加启动所有容器对应本地主机上海时间
    * 增加上传切片接口，用于上传切片数据
    * 网页端界面修改接口g对饮qanything，部分接口不可用，待后期继续完善

## 2024.10.15 —— commit：
* 修改：
    * 删除接口是删除目录，而不是文件（影响运行）
    * pdf解析过程可能出现空的，增加continue处理


## 2024.10.21 —— commit：
* 修改：
    * 新增联网检索代理设置，使用clash，相关启动设置在entrypoint-gpu.sh中
    * 联网检索部分网络AsyncHtmlLoader获取超时，提取过滤网址
    * entrypoint-gpu.sh中，设置显卡环境变量，可以指定用哪张显卡



## todo:
    * 注意其他sanic服务启动如果超时（超过30s），需要设置超时时间 sanic.worker.manager.WorkerManager.THRESHOLD = 6000



## 2024.11.04 —— commit：
* 根据10.22前官方更新内容修改：
    * rerank socre改为两位小数
    * 删除知识库和文档时候，存储的图片文件一起删除
    * FIX: time_record过长导致插入mysql失败的bug
    * MOD：提高 rerank 结果的可区分性，并优化保留 rerank 结果的逻辑。
    * MOD: 优化指令，提升回答的逻辑和结构化
    * FIX: 跳过网络检索无title的结果
    * FIX: Embedding推理逻辑

* 去除user_id验证



## 2024.11.06 —— commit：
* 修改：
    * FIX: 修改embedding中变量多余的bug
    * MOD: 改进读取xlsx时，如果第一行是信息标题行，当做标题处理。
    * MOD: 修改文件转markdown时，不限制标题层级
    * MOD: 将原markdown解析的page_id(其实际意义是标题级别)替换为title_level


## 2024.11.08 —— commit：
* 修改：
    * FIX: 修改model_config中，prompt多余的部分
    * MOD: local_doc_qa中chat部分与最新代码同步
    * ADD: 增加local_doc_chat接口
    * ADD: 增加保存question_rag_search的记录到本地文件
    * MOD: xlsxi文件，不适用markdown进行解析，直接使用pandas解析成csv方案，一行一条进行存储 （***需要根据实际项目数据进行选择***）

## 2024.11.11 —— commit：
* 修改：
    * ADD: 检索接口，增加判断问题长度，如果问题长度小于指定值，则直接返回检索结果空
    * ADD: 在model_config中增加检索的得分阈值设置



## 2024.11.22 —— commit：
    * ADD: 新增question_qa_search检索，检索结果将qa与doc进行分开
    * ADD: upload_faqs接口增加上传faq存储是的file_id输入，增加判断是否有相同问题上传


## 2024.12.03   —— commit：
    * FIX: 当检索结果只有一个时，不用rerank，由于milvus检索使用 L2 范数，Score 可能是查询向量与返回向量之间的欧几里得距离的负值（因为距离越小，相似度越高）。所以score需要取反。
    * FIX: 删除文件时，误删除milvus中的知识库，修正bug
    * ADD: 增加向量库检索结果阈值筛选，滤除大于VECTOR_SEARCH_SCORE_THRESHOLD值的向量结果
    * FIX: 修正question_qa_search接口保存结果时字段不存在的bug
    * ADD: 检索结果最多返回5条

## 2024.12.05   —— commit：
    * ADD: 新增向量库对外接口，用于向量库增删改查
    * FIX: pdf文件页码会出现0页的情况，修正bug


## 2024.12.25   —— commit：
    * FIX: pdf文件有页码时，页码被split导致读取页码循环错误，修正bug，方法为最后在保存markdown文档时，将页码信息以文字的方式插入到文档中，解析时按照正则匹配进行提取
    * FIX: delete_docs接口，删除文档时，file_info读取错误，修正bug
    * ADD: 添加pt模型torch推理，用于npu推理
    * ADD: 新增联网检索插件"WikipediaSearch","DuckDuckGoSearch","BaiduSearch"
    * ADD: 新增检索插件设置

## 2024.12.30   —— commit：
    * MOD: 修改检索结果，网页检索结果单独增加一个字段，用于区分
    * MOD: 只有一个检索结果时，也进行rerank，计算socre，用于筛选
    * ADD: 新增检索msg信息，主要用于记录检索的msg信息，方便后续排查问题
    * ADD: 新增百度百科检索插件，BaiduBaike
    

## 2025.01.14   —— commit：
    * MOD: 修改qa匹配位置，在rerank前进行qa完全匹配，匹配上则直接返回，不再进行rerank
    * ADD: OCR服务增加“ocr_detect”和“ocr_recognizer”api，用于检测文字框和识别框图中的文字
    * ADD: PDF解析服务增加“pdfparser_chunk”api，用于分块解析pdf，同时解决图片式pdf解析不成功问题。该解析方法使用ocr读取，具体细节参考源代码
    * ADD: 新增测试ocr服务demo脚本

## 2025.01.15   —— commit：
    * MOD: 修改query_rewrite接口，新增模型参数输入，用于query_rewrite的模型选择，默认获取模型第一个
    * MOD: 界面信息进行修改，替换为BMP标签，链接元景

## 2025.01.26   —— commit：
    * ADD: 增加chunk server
    * ADD: 增加docx文档详情解析，增加表格以及内容的解析

## 2025.02.07   —— commit：
    * MOD: 修正get_files_statu中，file_id不存在时仍然正常返回的bug
    * ADD：pdf解析的chunk中，增加该chunk内容的bboxes, bboxes格式为[[x0,x1,y0,y1,pn],[x0,x1,y0,y1,pn],...]
    * ADD: get_doc_completed接口中，增加判断知识库和文件不存在的情况，返回错误信息
    * ADD: chunk_summary接口增加了提取关键词和QA对的功能，具体参考源代码

## 2025.02.20   —— commit：
    * 增加检索指定file_id的文件
    * ADD: chunk_summary接口中，增加将chunk内容提取的"keywords"和"qa"保存到mysql中的Documents表中json_data，后续可以在get_doc_completed接口中直接查询返回
    

## 2025.02.25   —— commit：
    * ADD: 新增检索时设置得分阈值score_threshold，用于过滤检索结果，默认值0.5
    * MOD: 增加单个文件的字数限制1000W字，超过则不解析
    * MOD: 增加docker-compose启动的容器非手动关闭情况下自动重启



## 2025.02.27   —— commit：
    * MOD: sanic服务embedding和rerank设置为60秒超时，避免超时导致服务异常
    * MOD: 增加离线时，设置环境变量，自动检测是否能够连接互联网
    * ADD: torch npu推理增加指定显卡id的功能
    * MOD: 取消pdf解析时，接口超时时间，同时修改
    * MOD: 在insert server中，增加连接上milvus，先判断是否有这个collection，如果没有就创建。避免第一次启动时报错没有qanything这个collection
    * MOD: 修改ocr提取的bbox的倾斜判断，斜着的情况下则滤除
    * MOD: 版面检测模型替换为ragflow中的yolov10，效果更好
    * MOD: arm版本es切换为8.13.2
    * MOD: docx解析使用docx进行解析，保存图片并解析表格
    * MOD: 组合切片时，不限制根据单个切片最短长度进行合并
    

## 2025.04.01   —— commit：
    * MOD: query 提取qa和提取关键词接口，针对大模型输出，做格式正则化匹配
    * MOD: es 检索增加file_id指定或者kb_id指定
    * MOD: faq 不对file_name做简化，避免名称一致
    * MOD：上传文件，删除文件名称中的空格
    * MOD: insert_files_server中，解析完成插入milvus时，更改为定时进行flush(),避免插入时超时
    * MOD: get_files_statu接口中，针对file_id不存在的情况，返回文件状态为red，msg中说明详情
    * ADD: list_docs接口，增加返回内容中，将所有red状态的文件信息进行返回
    * ADD: chunk_summary接口中，api_base参数支持接口全路径，也支持openai格式的api_base
    * ADD: insert_files_server中，增加自动检测是否能够连接互联网，如果可以连接，则自动切换为联网模式，否则切换为离线模式，sanic.worker启动设置为6000，避免超时
    * ADD: pdf_parser_server中，sanic.worker启动设置为6000，避免超时
    * ADD: docker_compose启动的所有容器增加restart: unless-stopped，避免容器异常退出后，不自动重启
    * ADD: 新增图像nginx服务代理，在install_nginx.sh中，配置nginx端口，默认为80，model_config中配置IMAGES_PROXY_URL
    * ADD: 新增BMP接口批量上传文件脚本

    * MOD: 上传faq接口，更改answer长度限制，从2048改为8000，注意，以前部署的版本需要手动修改faq表中的answer长度。
    * MOD: 新制作nvidia环境的docker镜像，将模型移除镜像，并对代码做适应更新，方便后续模型更新替换
    

## 2025.04.02   —— commit：
    * MOD: pdf解析服务中，表格解析服务修改使用gpu
    * MOD: 修改docker镜像制作相关依赖环境，onnxruntime需要指定进行安装，直接安装依赖问题会报错



## 2025.04.10   —— commit：
    * ADD: 更改检索接口，新增ignore_file_error参数，默认为True，如果文件不存在或者知识库不存在，不返回报错，仍检索存在的结果
    * ADD: 新增rerank服务和embedding服务调用通用其他接口模板，需要对local_doc_qa.py中的embeddings和rerank实例化时修改
    * ADD: 新增接口modify_file_info，用于修改文件提取的关键词和QA对以及总结，修改文件id对应的Documents表中的json_data字段，结果可以使用get_doc_completed获取查看
    * MOD: 优化docx解析时，docx中表格超长，按照表格行数和字数进行拆分，避免表格内容过多，单个chunk过长
    * MOD: 优化xlsx解析，新增解析含多行title，新增判断表格是简单表格还是复杂表格，简单表格存成csv，按单行解析chunk，复杂表格按html格式保存chunk，按行和字数进行拆分



## 2025.04.16   —— commit：
    * MOD: 修复docx解析时，图像解析错误，导致解析失败，修正bug
    * MOD: modify_file_info接口不再判断kb_id和file_id，直接判断doc_id，如果doc_id不存在，则不进行修改
    * MOD: 修复pdf解析时，表格解析html转markdown时，对合并单元格的解析错误，导致行列错位。合并的直接使用合并值进行填充


## 2025.04.18   —— commit：
    * ADD: upload_faqs中，增加文件上传功能
    * ADD: 前端界面更新到2.0.6版本，修复机器人模型配置llm_config问题
    * MOD: 将qanything的服务端口以及workers统一配置到model_config中，方便后续修改
    * MOD: delete_knowledge_base接口新增批量删除知识库，读取参数kb_ids    


## 2025.04.25   —— commit：
    * MOD: 修复rerank配置端口错误问题
    * ADD: list_kbs中，增加上传kb_id参数，用于指定返回的kb_id的信息，默认为空，返回所有kb_id的信息。并且增加返回知识库的所有详细信息kb_metadata，parser_config，creation_time
    * ADD: 增加上传chunk时，修改在保存时仍然做了parents切分，按chunk保存。便于如文章摘要等功能使用
    * ADD: 增加增删改查知识库的metadata，用于保存知识库的元信息，可以自定义。/api/add_metadata接口用于增删改，/api/qanything/list_knowledge_base用于查询
    * ADD: 增加对接dify的查询接口。/retrieval
    * MOD: 修改前端电话信息等。



    * bug修复: 优化表格中仅一列的情况，原方案会把所有内容作为title+html表格，解析时就不会做parent_split，可能导致切片过长。优化后，会把所有内容当做title内容
    * bug修复: 不同用户，创建相同知识库ID,导致知识库ID冲突,仍然返回创建成功


## 2025.05.14   —— commit：
    * ADD: 针对bf12315项目，新增公司名称检索接口，/api/rag_entity_match
    * ADD: 针对docx文档，解析时， 增加解析“第XX条”，将条款内容不切分，最多单条5000字，且表格单独提取，将表格介绍段和表格放在一起
    * ADD: 检索接口增加"merge"参数，默认为True，如果为True，则合并检索结果中同一个文件的不同切片，socre取最大值，如果为False，则不合并，直接返回所有检索结果
    * MOD: local_doc_chat接口，修改query改写，深度思考模型替换掉<think>过程，增加检索rerank_score设置
    * MOD: 知识库检索接口，从向量库检索VECTOR_SEARCH_TOP_K，rerank后再取TOP_K，默认为5
    * MOD: 去掉简单表格解析转置数据，且单行表格作为一个chunk，不再合并，也不再做parent切分
    * MOD: 调用接口存储部分将文件json格式化，便于后续查看
    * ADD: embedding服务和rerank服务增加general api，用于通用调用，同时rag服务中，可以切换访问其他的embedding和rerank服务



## 2025.05.23   —— commit：
    * MOD: 修改解析过程，每个切片增加一个metadata信息“single_parent”，如果为True，则表示该切片是单父节点，不进行parent切分，否则进行parent切分。
    * MOD: 自动切分符号："\n[chunk-split]\n"
    * MOD: txt文档如果包含自动切分文档，这设置“single_parent”为True，避免切分
    * MOD: xlsx文档，每行进行切分，不进行parent切分
    * MOD: docx文档，增加按自动切分符号切分，切分后的内容会继续按照parent切分
    * MOD: "rag_entity_match"接口bug修复
    * MOD: 新增pdf解析时，保存版面检测结果，表格用html格式替换，并增加表格的caption
    * MOD: docx表格解析，合并单元格优化
    * MOD: 8777端口转发8772端口的general_rerank服务
    


## 2025.06.04   —— commit：
    * ADD: 新增提取备份数据中qa的脚本
    * MOD: 修正检索结果merge时，qa数据没有faq_dict字段问题
    * MOD: 修改，保存上传文件的文件名中的特殊符号
    * MOD: 修正docx解析中，表格超长，拆分时变量错误使用的bug
    * MOD: 修正保存qa本地文件时，文件名过长的bug
    

## 2025.06.06   —— commit：
    * MOD: 优化mysql中查询Files状态数量时，避免查询时，如果数据量过大，导致查询超时
    * MOD: 图像存储目录更换，便于备份数据，同步更新图像代理地址
    * MOD: qa的rerank不加入answer
    * MOD: 图片保存目录切换到QANY_DB/file_images中
    * BUG: 检索时，如果有较多qa，将其统计状态时特别耗时，优化mysql查询方式，避免超时


## 2025.06.11   —— commit：
    * MOD: 优化长图ocr识别，将长图切分成多张图片，每张图片进行ocr识别，再合并结果
    * MOD: 修复bug

## 2025.06.13   —— commit：
    * ADD: 前端界面user_info信息更改为user_id,user_info默认为“1234”，便于不同项目下前端切换用户显示
    * MOD: 切片更新接口，将切片长度限制为2*chunk_size，便于修改切片时有部分超长
    * BUG: 问题修复，ocr接口resize后，没有将图像bbox恢复到原来的scale
    * ADD: 增加联网搜索BingSearch，修复联网搜索BaiduSearch


## 2025.06.20   —— commit：
    * MOD: get_doc_completed接口取消kb_id参数，自动根据file_id进行校验
    * MOD: 修复bingsearch不生效问题
    * MOD: chunk_summary接口去掉kb_id参数，自动根据file_id进行校验
    * ADD: 新增file_extract_summary_outline接口，用于提取文件摘要和目录大纲，自动根据file_id进行校验（返回后，用户可手动修改，利用切片上传功能，实现多种功能）
    * ADD: 新增配置本地大模型，model_config中LLM模型调用参数
    * ADD: /api/qanything/document_parser_embedding接口，新增输入参数“parser_outline”，“parser_summary”，默认为False，如果为True，则自动提取文件摘要和整个文件大纲，需要配置model_config中LLM模型调用参数
    * MOD: get_files_statu接口删除kb_id参数，根据file_id进行校验
    * MOD: 大模型调用过程，增加去掉深度思考内容
    * MOD: 修改query改写提示词，更新query改写接口


## 2025.07.15   —— commit：
    * MOD: 针对较长文档，摘要总结和大纲提取循环调用大模型，避免仍然超token长度，增加调用时间
    * MOD: 修改大纲提取提示词
    * MOD: 增加解析超时时间设置
    * ADD: 检索接口，增加history参数，用于query改写，如果有输入history，且本地配置的模型可以调用，则调用query改写后再进行检索（后续优化方式，将单个问题拆成多个进行检索改写）
    * ADD: 上传时如果没有选择生成大纲和摘要，可以调用接口生成，file_extract_outline，file_extract_summary
    * ADD: 增加知识库层级元数据增删改查，"list_kbs"搭配"update_kb_metadata"
    * ADD: 增加文件层级元数据增删改查, "list_docs"搭配"update_file_metadata"
    * ADD: 增加切片层级元数据增删改查, "get_doc_completed"搭配"modify_chunk_kwargs"
    

## 2025.07.25   —— commit：
    * MOD: 更换前端图标
    * MOD: 对接dify接口，调试，元数据对应到文件
    * MOD: 修复pdf切片时，长表格无text时过长的bug
    * ADD: 新增长docx文档提取大纲部分，直接用目录替换，不用大模型
    * MOD: 优化各个服务的内存占用情况
    * MOD: 优化ocr服务


## TAG V2.2


## 2025.08.13   —— commit：
    * 容器对应的docker数据替换为docker volumes
    * 各个容器端口不暴露，RAGnetwork为容器间通信，对外只保留服务端口
    * rerank服务由于可能超长，增加切断功能；embeding由于child chunk，不会超过512token，不需要切断
    * 增加arm架构cpu的docker compose配置文件
    * 前端删除QAnything标识
    * 混合检索默认开启
    * 删除针对项目接口，项目定开单独开分支维护
    * 所有对外api接口更换为/api/rag/xxx
    

## 2025.08.28   —— commit：
    * x86 版本milvus替换为 v2.5.10，有milvus可视化前端
    * local_file中，保存文件增加异常处理
    * 图像代理的ip通过docker compose文件环境变量配置，不再手动修改
    * 修改run.sh，一键部署脚本

## TAG V2.3



## 2025.09.08   —— commit：
    * MOD: 知识库id是不能重复的，但是在不同的用户下，创建相同知识库id，不会提示冲突，需要修改（bug）
    * MOD: 修改切片修改接口，不再限制切片内容的长度（个别表格切片较长）。
    * MOD: 修正摘要总结和大纲提取接口调用bug。
    * MOD: 更新api说明
    * MOD: 修改上传文件名称的长度限制为new_filename.encode('utf-8')长度200 
    * MOD: 修改删除文件时，结果删除了整个知识库文件夹
    * ADD: list_files，查询知识库文件情况，新增查询条件，file_name和status解析状态
    * ADD: 增加修改qa接口，"/api/rag/update_qa"
    * ADD: 增加知识库查询条件：知识库名称筛选
    * ADD: 增加切片删除接口，"/api/rag/delete_chunks"
    * ADD: 移动复制文件接口，"/api/rag/move_file"



## 2025.09.15   —— commit：
    * BUG修复: qestion_qa_search接口，参数未什么错误修复
    * BUG修复: es检索接口，数据存储未保存doc_id，多余其他字段信息。
    * BUG修复: 部署完成后，上传了文件，但是检索结果是空的。需要重启容器后milvus才能正常检索

## TAG V2.4


## 2025.09.18   —— commit：
    * MOD: 修改调用请求存储路径bug
    * MOD: 修改默认LOCAL_RERANK_BATCH=4，LOCAL_EMBED_BATCH=4
    * MOD: 调用请求保存路径更改为统一的路径，./retrieval_record/api_calls_{date}.csv
    * MOD: 统一所有接口错误返回code，400 请求输入参数错误；401 超过知识限制；500 接口内部错误；200 成功
    * MOD: 更改提取大纲和摘要的新文件不再创建新的知识库保存，直接保存到原来的知识库中
    * ADD: 增加切片参数修改，修改切片标点符号，修改切片长度，每个知识库配置一个参数，自带默认值，创建知识库时，添加参数
    * ADD: 增加知识库可选embedding模型，可以在创建知识库时配置，一旦创建，则不能修改，带默认值
    * ADD: 增加检索接口可选rerank模型，带默认值
    * ADD: 将所有token计算为token数，统一使用encoding = tiktoken.encoding_for_model('gpt-3.5-turbo-0613')，nvidia版本内存占用由13G降低到8.5G


## TAG V2.5



# TODO:
    * 知识图谱构建
    * mysql存储一个历史问题请求记录表，记录用户id，知识库id，文件id，切片id，问题，回答，时间，用于后续分析
    * 增加切片种类，参考ragflow方式，保留当前优化后的切片方案
    
    
    

    
    
    
  
    

